{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Hotel Reservation\"\n",
        "author: \n",
        "  - Nastaran  Mesgari\n",
        "\n",
        "\n",
        "abstract: \" \"\n",
        "\n",
        "format: \n",
        "  html:\n",
        "    code-fold: False\n",
        "    standalone: true\n",
        "    embed-resources: true\n",
        "    toc: true\n",
        "---"
      ],
      "id": "a608e93e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction\n",
        "\n",
        "\n",
        "## 2. Data Set\n",
        "### 2.1\tHotel Reservation Data set\n",
        "\n",
        "\n",
        "## 3. Data Recognition\n",
        "As the first step, we need to import the main libraries to start analysis.\n"
      ],
      "id": "d46da048"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: import-libraries\n",
        "# importing main libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_ind\n",
        "import warnings\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "import-libraries",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Loading Data\n",
        "To use data, we need to import them and read the data. In this case, our data is CSV files, and it is in the folder whose name is data."
      ],
      "id": "491c851f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-import\n",
        "df = pd.read_csv('data\\HotelReservations.csv')\n",
        "df.head() "
      ],
      "id": "data-import",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: show how many rows and coloumn in data set\n",
        "df.shape"
      ],
      "id": "show-how-many-rows-and-coloumn-in-data-set",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With this function, we check all culmns and their type. "
      ],
      "id": "7e909939"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Get informaion\n",
        "# getting data on dataset\n",
        "df.info()"
      ],
      "id": "Get-informaion",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Pre-processing\n",
        "This process is beneficial for several reasons. Reducing dimensionality, improving computational efficiency and enhancing model performance.\n",
        "In the pre-processing step, dimension reduction, outlier detection and missing value handling were conducted.\n",
        "\n",
        "### 4.1. Dropping unnecessary columns and rows:\n",
        "Dropping unnecessary columns and rows is a data preprocessing step that involves removing specific columns or rows from a dataset that are deemed unnecessary for the analysis or modeling task at hand. \n",
        " We selected the best columns using the feature selection algorithm and we will obtain the accuracy of the model before and after that.\n",
        "\n",
        "\n",
        "#### 4.2. Checking missing values\n",
        "In most cases, we do not get complete datasets. They either have some missing values in the rows and columns. However, fortunately, we check whether the dataset has any missing values or not, and as you can see in the output of the block below, there is no missing value in this dataset\n"
      ],
      "id": "3ca6ec37"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Drop rows with null values\n",
        "df = df.dropna()\n",
        "df.info()\n",
        "df.shape"
      ],
      "id": "fcb17640",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Checking for missing values in the entire dataset\n",
        "missing_values = df.isnull().sum()\n",
        "# Printing the result\n",
        "print(missing_values)"
      ],
      "id": "f14cd57c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### \t4.3 Checking for garbage values\n",
        "Garbage value is generally a term meaning that the value in a variable which means nothing.\n",
        "By checking the statistical information of the data, some variables have negative values, and some have 0 values which are not compatible with the definition (corresponding to the dataset).\n",
        "The detail of these values is given in the following tables:\n",
        " *** Negative Values and Ziro for deleting ***\n",
        " Using this code, we check the data for minus and zero values if they are not compatible by the meaning they have."
      ],
      "id": "c29f5d2f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "md-indent": " "
      },
      "source": [
        "# get name the columns\n",
        "df.columns"
      ],
      "id": "b5c7f2e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Checking the negative values of no_of_adults\n",
        "for column in df.columns:\n",
        "    print(df[column].value_counts())"
      ],
      "id": "0ddc57a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As shown above, there are no undefined values in each variables. Therefore, we omit no cases.\n",
        "\n",
        "### 4.4 Checking the distribution of each variable \n",
        "Checking the distribution of each variable involves examining the spread and pattern of values within individual columns or features in the dataset. Understanding the distribution helps you gain insights into the central tendencies, variability, and shape of the data. This is crucial for making informed decisions during data analysis and modeling. Common statistical measures used to describe the distribution include mean, median, and standard deviation.\n",
        ".\n"
      ],
      "id": "a54253d8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# check the distribution for each column\n",
        "df.describe().T"
      ],
      "id": "bead419c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using this code, the most important statistical information of each numeric predictiors are calculated."
      ],
      "id": "36a7b082"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_numeric = df.select_dtypes(include=np.number)\n",
        "df_numeric.shape"
      ],
      "id": "a44c9e3f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# finding zero variance variables\n",
        "selector_vr= VarianceThreshold(threshold=0)\n",
        "selector_vr.fit_transform(df_numeric)\n",
        "#selector_vr.get_support(indices=True)"
      ],
      "id": "2330fa15",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If there are variables with standard deviation near the zero , we can delete it . \n"
      ],
      "id": "6285bcca"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.head()\n",
        "df.columns"
      ],
      "id": "33ac1f70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we check the categorical variables and their categories to show the frequency of each values.\n",
        "\n",
        "Histograms are useful for analyzing the frequency distribution of different values for each variable. In each histogram, the horizontal axis represents the variable values, and the vertical axis indicates the frequency or the number of times each value appears in the data. The height of each column reflects the frequency or the number of samples with a specific value in that interval.\n"
      ],
      "id": "86049ded"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Specify the columns you want to include in the analysis\n",
        "selected_columns = ['Booking_ID', 'no_of_adults', 'no_of_children', 'no_of_weekend_nights',\n",
        "       'no_of_week_nights', 'type_of_meal_plan', 'required_car_parking_space',\n",
        "       'room_type_reserved', 'lead_time', 'arrival_year', 'arrival_month',\n",
        "       'arrival_date', 'market_segment_type', 'repeated_guest',\n",
        "       'no_of_previous_cancellations', 'no_of_previous_bookings_not_canceled',\n",
        "       'avg_price_per_room', 'no_of_special_requests', 'booking_status']\n",
        "\n",
        "# Create a DataFrame containing only the selected columns\n",
        "selected_df = df[selected_columns]\n",
        "\n",
        "# Plot histograms for each variable\n",
        "selected_df.hist(figsize=(10, 8))\n",
        "plt.suptitle('Histograms of Selected Variables')\n",
        "plt.show()"
      ],
      "id": "c11add69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Displaying some statistics about categorical data\n",
        "df.describe(include='object')"
      ],
      "id": "846bb123",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Data Transformation\n",
        "\n",
        "#### 4.5.1 Transforming the categorical variables\n",
        "In this step, we numerized object variables . As it mentioned earlier, booking_status and target has two object:Not_Canceled\n",
        ", Canceled\n",
        ". For efficient use in the models, we convert Canceled\n",
        " to 1 and Not_Canceled to 0.\n",
        "If we have a column that is object or if we have Boolean, we can convert them to integer. In this stage I use the new data frame for own data with own selected column for better decision in the following steps."
      ],
      "id": "0e8e5015"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.describe()"
      ],
      "id": "0aa80de5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#using Map Function\n",
        "df2 = df.copy()\n",
        "\n",
        "# Ordinal Encoding for booking_status: 1 for 'Canceled', 0 for 'Not_Canceled'\n",
        "ordinal_map = {'Canceled': 1, 'Not_Canceled': 0}\n",
        "df2['booking_status'] = df2['booking_status'].map(ordinal_map)\n",
        "df2['booking_status'] = df2['booking_status'].astype(int)"
      ],
      "id": "f5f96cfb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check again the structure of the dataframe."
      ],
      "id": "5cf234ec"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#df2.info()\n",
        "#df2.head()\n",
        "#df2.shape\n",
        "unique_values = df2['type_of_meal_plan'].unique()\n",
        "print(unique_values)"
      ],
      "id": "229a999a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get unique values in the column\n",
        "unique_values = df2['booking_status'].unique()\n",
        "print(unique_values)"
      ],
      "id": "61045273",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.5.2 Normalization, standardization, scaling\n"
      ],
      "id": "30d10bf9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}